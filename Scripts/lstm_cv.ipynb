{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import welch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_num = 2\n",
    "\n",
    "eeg_task_path = f'../Data/Processed/sub0{patient_num}_binned_task.csv'\n",
    "eeg_data = pd.read_csv(eeg_task_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout_rate=0.5):\n",
    "        super(EEG_LSTM, self).__init__()\n",
    "        # Apply dropout only if num_layers > 1\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True, \n",
    "                            dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, n_electrodes, n_time_steps, window_size = x.shape\n",
    "        x = x.view(batch_size, n_time_steps, n_electrodes * window_size)\n",
    "        lstm_out, (hn, _) = self.lstm(x)\n",
    "        out = self.bn(hn[-1])\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(eeg_data, selected_electrodes, window_size, step_size):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for idx, row in eeg_data.iterrows():\n",
    "        trial_data = []\n",
    "        for electrode in selected_electrodes:\n",
    "            # Convert the string representation to a list of floats\n",
    "            signal = np.array(eval(row[electrode]))\n",
    "            # Extract sliding windows\n",
    "            windows = [\n",
    "                signal[i:i + window_size]\n",
    "                for i in range(0, len(signal) - window_size + 1, step_size)\n",
    "            ]\n",
    "            if len(windows) > 0:\n",
    "                windows = [(window - np.mean(window)) / np.std(window) for window in windows]\n",
    "                trial_data.append(np.array(windows))\n",
    "        if len(trial_data) == len(selected_electrodes):\n",
    "            trial_data = np.array(trial_data)  # Shape: (n_electrodes, n_time_steps, window_size)\n",
    "            sequences.append(trial_data)\n",
    "            label = 1 if row['label_type'] == 'social' else 0\n",
    "            labels.append(label)\n",
    "    X = np.array(sequences)\n",
    "    y = np.array(labels)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(y_batch.numpy())\n",
    "    return accuracy_score(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(eeg_data, selected_electrodes, hyperparams, device='cuda'):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    for hidden_size in hyperparams['hidden_size']:\n",
    "        for num_layers in hyperparams['num_layers']:\n",
    "            for dropout_rate in hyperparams['dropout_rate']:\n",
    "                for lr in hyperparams['learning_rate']:\n",
    "                    for window_size in hyperparams['window_size']:\n",
    "                        for step_size in hyperparams['step_size']:\n",
    "                            for batch_size in hyperparams['batch_size']:\n",
    "                                print(f\"Testing params: hidden_size={hidden_size}, num_layers={num_layers}, \"\n",
    "                                      f\"dropout={dropout_rate}, lr={lr}, window_size={window_size}, step_size={step_size}, batch_size={batch_size}\")\n",
    "                                \n",
    "                                # Extract features with the current window and step size\n",
    "                                X, y = extract_sliding_windows(eeg_data, selected_electrodes, window_size, step_size)\n",
    "                                if X.shape[0] == 0:\n",
    "                                    continue  # Skip if no data was extracted\n",
    "                                \n",
    "                                n_electrodes = X.shape[1]\n",
    "                                actual_window_size = X.shape[3]\n",
    "                                input_size = n_electrodes * actual_window_size\n",
    "                                print(f\"Calculated input_size: {input_size}\")\n",
    "\n",
    "                                scores = []\n",
    "\n",
    "                                for train_idx, val_idx in skf.split(X, y):\n",
    "                                    X_train, X_val = X[train_idx], X[val_idx]\n",
    "                                    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "                                    train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                                                                   torch.tensor(y_train, dtype=torch.long))\n",
    "                                    val_dataset = torch.utils.data.TensorDataset(torch.tensor(X_val, dtype=torch.float32),\n",
    "                                                                                 torch.tensor(y_val, dtype=torch.long))\n",
    "                                    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                                    model = EEG_LSTM(input_size=input_size, hidden_size=hidden_size, \n",
    "                                                     num_layers=num_layers, output_size=2, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "                                    criterion = nn.CrossEntropyLoss()\n",
    "                                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                                    train_model(model, train_loader, criterion, optimizer, device)\n",
    "                                    accuracy = evaluate_model(model, val_loader, device)\n",
    "                                    scores.append(accuracy)\n",
    "\n",
    "                                avg_score = np.mean(scores)\n",
    "                                if avg_score > best_score:\n",
    "                                    best_score = avg_score\n",
    "                                    best_params = {\n",
    "                                        'hidden_size': hidden_size,\n",
    "                                        'num_layers': num_layers,\n",
    "                                        'dropout_rate': dropout_rate,\n",
    "                                        'learning_rate': lr,\n",
    "                                        'window_size': window_size,\n",
    "                                        'step_size': step_size,\n",
    "                                        'batch_size': batch_size\n",
    "                                    }\n",
    "                                print(f\"Params: {best_params}, Score: {avg_score:.4f}\")\n",
    "    \n",
    "    print(f\"Best Hyperparameters: {best_params}, Best Score: {best_score:.4f}\")\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=8, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 8, 'batch_size': 16}, Score: 0.4980\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=8, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 8, 'batch_size': 32}, Score: 0.4987\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=8, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 8, 'batch_size': 32}, Score: 0.4925\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=16, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 8, 'batch_size': 32}, Score: 0.4923\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=16, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5455\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=16, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5110\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=32, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4889\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=32, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4766\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=32, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4768\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=48, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4826\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=48, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5206\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=32, step_size=48, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5237\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=8, batch_size=16\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5297\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=8, batch_size=32\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4918\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=8, batch_size=64\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4764\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=16, batch_size=16\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5109\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=16, batch_size=32\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4952\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=16, batch_size=64\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.5200\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=32, batch_size=16\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4984\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=32, batch_size=32\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4765\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=32, batch_size=64\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4671\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=48, batch_size=16\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 32, 'step_size': 16, 'batch_size': 32}, Score: 0.4863\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=48, batch_size=32\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5516\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=64, step_size=48, batch_size=64\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4827\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=8, batch_size=16\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4671\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=8, batch_size=32\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5017\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=8, batch_size=64\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4830\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=16, batch_size=16\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5299\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=16, batch_size=32\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4641\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=16, batch_size=64\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5454\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=32, batch_size=16\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4953\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=32, batch_size=32\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5300\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=32, batch_size=64\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4734\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=48, batch_size=16\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4825\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=48, batch_size=32\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5298\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=96, step_size=48, batch_size=64\n",
      "Calculated input_size: 2400\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5139\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=8, batch_size=16\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4706\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=8, batch_size=32\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5299\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=8, batch_size=64\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5297\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=16, batch_size=16\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4703\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=16, batch_size=32\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5015\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=16, batch_size=64\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4735\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=32, batch_size=16\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4485\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=32, batch_size=32\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5109\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=32, batch_size=64\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5112\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=48, batch_size=16\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5049\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=48, batch_size=32\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5269\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.001, window_size=128, step_size=48, batch_size=64\n",
      "Calculated input_size: 3200\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4734\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=8, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5080\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=8, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4640\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=8, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4704\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=16, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4578\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=16, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5076\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=16, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5111\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=32, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4391\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=32, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4546\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=32, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5297\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=48, batch_size=16\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4986\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=48, batch_size=32\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5363\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=32, step_size=48, batch_size=64\n",
      "Calculated input_size: 800\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4733\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=8, batch_size=16\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4638\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=8, batch_size=32\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5330\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=8, batch_size=64\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.5081\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=16, batch_size=16\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4859\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=16, batch_size=32\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4671\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=16, batch_size=64\n",
      "Calculated input_size: 1600\n",
      "Params: {'hidden_size': 32, 'num_layers': 1, 'dropout_rate': 0.0, 'learning_rate': 0.001, 'window_size': 64, 'step_size': 48, 'batch_size': 32}, Score: 0.4672\n",
      "Testing params: hidden_size=32, num_layers=1, dropout=0.0, lr=0.0005, window_size=64, step_size=32, batch_size=16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m selected_electrodes \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mO2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPO3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPO4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPO7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPO8\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAF3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAF4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAF7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAF8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFpz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT7\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFCz\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCP1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCP2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m ]\n\u001b[0;32m     17\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_electrodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Hyperparameters found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[31], line 17\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(eeg_data, selected_electrodes, hyperparams, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting params: hidden_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, num_layers=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, window_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, step_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, batch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Extract features with the current window and step size\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mextract_sliding_windows\u001b[49m\u001b[43m(\u001b[49m\u001b[43meeg_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_electrodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip if no data was extracted\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[28], line 18\u001b[0m, in \u001b[0;36mextract_sliding_windows\u001b[1;34m(eeg_data, selected_electrodes, window_size, step_size)\u001b[0m\n\u001b[0;32m     16\u001b[0m         trial_data\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(windows))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trial_data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(selected_electrodes):\n\u001b[1;32m---> 18\u001b[0m     trial_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial_data\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (n_electrodes, n_time_steps, window_size)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     sequences\u001b[38;5;241m.\u001b[39mappend(trial_data)\n\u001b[0;32m     20\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparams = {\n",
    "    'hidden_size': [32, 64, 128],         # Broader range of hidden sizes\n",
    "    'num_layers': [1, 2],                 # Keep it to 1 or 2 layers to avoid overfitting\n",
    "    'dropout_rate': [0.0, 0.3, 0.5],      # Include 0.0 (no dropout) for smaller models\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],  # Added intermediate learning rate\n",
    "    'window_size': [32, 64, 96, 128],         # Smaller window sizes to increase the number of samples\n",
    "    'step_size': [8, 16, 32, 48],            # Smaller step sizes for more overlap\n",
    "    'batch_size': [16, 32, 64]            # Try different batch sizes for better convergence\n",
    "}\n",
    "\n",
    "selected_electrodes = [\n",
    "    'O1', 'O2', 'Oz', 'POz', 'PO3', 'PO4', 'PO7', 'PO8',\n",
    "    'F3', 'F4', 'Fz', 'F7', 'F8', 'AF3', 'AF4', 'AF7', 'AF8', 'Fpz',\n",
    "    'T7', 'T8', 'Cz', 'Pz', 'FCz', 'CP1', 'CP2'\n",
    "]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "best_params = cross_validate(eeg_data, selected_electrodes, hyperparams, device=device)\n",
    "print(f\"Best Hyperparameters found: {best_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
